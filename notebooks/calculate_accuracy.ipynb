{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "from multiomics_benchmark import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your datasets\n",
    "datasets = ['brain','breast', 'colorectal', 'glioma', 'head_neck', 'kidney_renal','lung', \n",
    "            'lung_squamous',  'omics', 'ovarian', 'pan_kidney', 'PreE', \n",
    "            'stomach_esophageal', 'thyroid', 'uterine']\n",
    "\n",
    "# Define omics names for each dataset\n",
    "options = defaultdict(lambda: [\"Methylation\", \"miRNA\", \"RNA\", \"RPPA\", \"SCNV\"], \n",
    "                      {'omics': ['cfRNA', 'proteo_lum', 'serum_lum', 'microbiome', 'CyTOF', 'metabolome', 'proteo_som'],\n",
    "                       'PreE': ['cfRNA', 'lipidome', 'metabol-plasma', 'metabol-urine', 'proteome', 'microbiome'],\n",
    "                       'glioma': [\"Methylation\", \"miRNA\", \"RNA\", \"RPPA\", \"SCNV\"],\n",
    "                       'brain': [\"Methylation\", \"miRNA\", \"RNA\", \"RPPA\", \"SCNV\"],\n",
    "                       'ovarian': [\"Methylation\", \"miRNA\", \"RNA\", \"RPPA\", \"SCNV\"],\n",
    "                       'uterine':[\"Methylation\", \"miRNA\", \"RPPA\", \"SCNV\"]\n",
    "                      })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What you want your accuracy threshold to be\n",
    "r_limit = 0.5\n",
    "r_limit_name = 'limit_{}'.format(r_limit)\n",
    "\n",
    "r_p_all = []\n",
    "n_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 1/15 [00:17<04:00, 17.17s/it]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:30<03:27, 15.98s/it]\u001b[A\n",
      " 20%|██        | 3/15 [00:42<02:59, 14.97s/it]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:56<02:38, 14.44s/it]\u001b[A\n",
      " 33%|███▎      | 5/15 [01:10<02:22, 14.29s/it]\u001b[A\n",
      " 40%|████      | 6/15 [01:25<02:10, 14.48s/it]\u001b[A\n",
      " 47%|████▋     | 7/15 [01:39<01:54, 14.33s/it]\u001b[A\n",
      " 53%|█████▎    | 8/15 [01:50<01:33, 13.36s/it]\u001b[A\n",
      " 60%|██████    | 9/15 [02:13<01:38, 16.49s/it]\u001b[A\n",
      " 67%|██████▋   | 10/15 [02:29<01:21, 16.33s/it]\u001b[A\n",
      " 73%|███████▎  | 11/15 [02:45<01:04, 16.22s/it]\u001b[A\n",
      " 80%|████████  | 12/15 [03:01<00:48, 16.03s/it]\u001b[A\n",
      " 87%|████████▋ | 13/15 [03:19<00:33, 16.75s/it]\u001b[A\n",
      " 93%|█████████▎| 14/15 [03:36<00:16, 16.82s/it]\u001b[A\n",
      "100%|██████████| 15/15 [03:46<00:00, 15.13s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "for dataset_index in tqdm(range(len(datasets))):\n",
    "    \n",
    "    dataset = datasets[dataset_index]\n",
    "    omics = options[dataset]\n",
    "\n",
    "    os.chdir('/home/mxenoc/workspace/multiomics-benchmark/results/'+dataset+'/')\n",
    "\n",
    "    feats_list = []\n",
    "\n",
    "    for i in range(len(omics)): feats_list.append(np.tile(omics[i],n_samples))\n",
    "        \n",
    "    feats = np.hstack(feats_list)\n",
    "\n",
    "    EN = dict()\n",
    "    GFA = dict()\n",
    "    Lasso = dict()\n",
    "    MT_Lasso = dict()\n",
    "    RF = dict()\n",
    "    group_lasso = dict()\n",
    "    blockForest = dict()\n",
    "    ridge = dict()\n",
    "\n",
    "    mdl =      [EN,    Lasso,   group_lasso,   RF,    ridge,   blockForest,   GFA,   MT_Lasso]\n",
    "    mdl_name = ['EN', 'Lasso', 'group_lasso', 'RF',  'ridge', 'blockForest', 'GFA', 'MT_Lasso']\n",
    "\n",
    "    for k in range(len(mdl_name)):\n",
    "        with open(f\"{mdl_name[k]}.pkl\", 'rb') as f:\n",
    "            mdl[k] = pickle.load(f)\n",
    "\n",
    "    r_p_list = []\n",
    "    models_res = []\n",
    "    res = []    \n",
    "\n",
    "    for i in range(len(mdl_name)-2): #loop through the models\n",
    "\n",
    "        all_features = defaultdict(list)\n",
    "\n",
    "        for l in range(len(omics)):   #loop through the modalities\n",
    "            each_feature = defaultdict(list)\n",
    "\n",
    "            for k in range(n_samples):   #loop through the targets\n",
    "\n",
    "                x = mdl[i]['observed_test'][l][k]\n",
    "                y = mdl[i]['prediction_test'][l][k]\n",
    "                y.iloc[0,0] += 0.0000000001\n",
    "\n",
    "                each_feature['r'].append(stats.spearmanr(x, y)[0])                \n",
    "                each_feature['p'].append(stats.spearmanr(x, y)[1])\n",
    "\n",
    "            all_features['r'].append(each_feature['r'])\n",
    "            all_features['p'].append(each_feature['p'])\n",
    "\n",
    "        r = np.hstack(all_features['r'])\n",
    "        p = np.hstack(all_features['p'])\n",
    "\n",
    "        r_p = pd.DataFrame({'r': r, 'p': p, 'omics': feats, 'model': mdl_name[i], 'data' : dataset})\n",
    "        r_p = r_p[(r_p['r']>r_limit) & (r_p['p']<=0.05)]\n",
    "        r_p_list.append(r_p)\n",
    "        res.append(len(r_p))\n",
    "\n",
    "    for n_GFA in ([len(mdl_name)-2, len(mdl_name)-1]):\n",
    "\n",
    "        all_features = defaultdict(list)\n",
    "\n",
    "        for l in range(len(omics)):\n",
    "            each_feature = defaultdict(list)\n",
    "\n",
    "            for k in range(n_samples):\n",
    "\n",
    "                x = mdl[n_GFA]['observed_test'][l][k]\n",
    "                y = mdl[n_GFA]['prediction_test'][l].iloc[:,k]\n",
    "                                \n",
    "                each_feature['r'].append(stats.spearmanr(x, y)[0])                \n",
    "                each_feature['p'].append(stats.spearmanr(x, y)[1])\n",
    "\n",
    "            all_features['r'].append(each_feature['r'])\n",
    "            all_features['p'].append(each_feature['p'])\n",
    "\n",
    "        r = np.hstack(all_features['r'])\n",
    "        p = np.hstack(all_features['p'])\n",
    "\n",
    "        r_p = pd.DataFrame({'r': r, 'p': p, 'omics': feats, 'model': mdl_name[n_GFA], 'data' : dataset})\n",
    "        r_p = r_p[(r_p['r']>r_limit) & (r_p['p']<=0.05)]\n",
    "        r_p_list.append(r_p)\n",
    "        res.append(len(r_p))\n",
    "\n",
    "    results = pd.DataFrame({'features': np.hstack(res), 'models': np.hstack(mdl_name), 'dataset': dataset})\n",
    "    results['percentage'] = results['features']/(len(omics)*n_samples)*100\n",
    "\n",
    "    r_p_all.append(pd.concat(r_p_list))\n",
    "    \n",
    "    os.chdir('/home/mxenoc/workspace/multiomics-benchmark/plots/accuracy_calculations/'+r_limit_name)\n",
    "    with open(dataset+'.pkl', 'wb') as f:  \n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy for individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_p_all = []\n",
    "individual_totals = {}\n",
    "\n",
    "r_limit = 0.5\n",
    "r_limit_name = 'limit_{}'.format(r_limit)\n",
    "\n",
    "#for dataset in datasets:\n",
    "for dataset in datasets:\n",
    "\n",
    "    omics = options[dataset]\n",
    "\n",
    "    with open('/home/mxenoc/workspace/multiomics-benchmark/results/'+dataset+'/individual/Lasso.pkl', 'rb') as f:\n",
    "        mdl = pickle.load(f)\n",
    "\n",
    "    r_p_list = []\n",
    "    models_res = []\n",
    "    res = []    \n",
    "\n",
    "    for omic_dataset in range(len(omics)):\n",
    "        all_features = defaultdict(list)\n",
    "        for k in range(n_samples):\n",
    "            each_feature = defaultdict(list)\n",
    "            for l in range(len(omics)-1):                \n",
    "\n",
    "                x = mdl['observed_test'][omic_dataset][k]\n",
    "                y = mdl['prediction_test'][omic_dataset][k][l]\n",
    "\n",
    "                each_feature['r'].append(stats.spearmanr(x,y)[0])                \n",
    "                each_feature['p'].append(stats.spearmanr(x,y)[1])\n",
    "                each_feature['predictor'].append(omics[l])\n",
    "\n",
    "            all_features['r'].append(each_feature['r'])\n",
    "            all_features['p'].append(each_feature['p'])\n",
    "            all_features['predictor'].append(each_feature['predictor'])\n",
    "\n",
    "        r = np.hstack(all_features['r'])\n",
    "        p = np.hstack(all_features['p'])\n",
    "        predictors = np.hstack(all_features['predictor'])\n",
    "\n",
    "        r_p = pd.DataFrame({'r': r, 'p': p, 'predictor': predictors, 'target': omics[omic_dataset]})\n",
    "        r_p = r_p[(r_p['r']>r_limit) & (r_p['p']<=0.05)]\n",
    "        r_p_list.append(r_p)\n",
    "        res.append(len(r_p))\n",
    "\n",
    "    test = pd.concat(r_p_list)\n",
    "    test = test.drop(['r', 'p'], axis = 1)\n",
    "\n",
    "    dataset_predictability = Counter(test['target'])\n",
    "    dataset_predictability = pd.DataFrame(dataset_predictability.items())\n",
    "    dataset_predictability.columns = ['features', 'group']\n",
    "\n",
    "    dataset_predictors = Counter(test['predictor'])\n",
    "    dataset_predictors = pd.DataFrame(dataset_predictors.items())\n",
    "    dataset_predictors.columns = ['features', 'group']\n",
    "\n",
    "    links = pd.DataFrame(test.groupby(test.columns.tolist(),as_index=False).size())\n",
    "    links.reset_index(level=0, inplace=True)\n",
    "    links.reset_index(level=0, inplace=True)\n",
    "    columns_titles = [\"predictor\",\"target\", 0]\n",
    "    links = links.reindex(columns = columns_titles)\n",
    "    links.columns = ['var1', 'var2', 'weight']\n",
    "\n",
    "    ###DO NOT USE THIS FOR MULTIOMICS AND PREE\n",
    "    links['var1'] = links['var1'].str.partition('_')[0]\n",
    "    links['var2'] = links['var2'].str.partition('_')[0]\n",
    "    #######\n",
    "\n",
    "    G = nx.from_pandas_edgelist(links, 'var1', 'var2', edge_attr=True, create_using=nx.DiGraph())\n",
    "\n",
    "    # Edges you want to include\n",
    "    threshold = 0\n",
    "\n",
    "    # Edges you want to plot\n",
    "    edges_filtered = [(u,v) for (u, v, e) in G.edges(data=True) if e['weight'] > threshold]\n",
    "    weights_filtered = [e['weight'] for (u, v, e) in G.edges(data=True) if e['weight'] > threshold]\n",
    "\n",
    "    # Choose the layout\n",
    "    pos = nx.spring_layout(G, scale = 0.5, k = 0.65)\n",
    "\n",
    "    node_colors = dataset_predictability.set_index('features')\n",
    "    # Reindex your nodes to match the graph's nodes\n",
    "    node_colors_reind = node_colors.reindex(G.nodes())\n",
    "    #node_colors_reind['group'] = pd.Categorical(node_colors_reind['group'])\n",
    "    node_colors_percent = (node_colors_reind/((len(omics)-1)*50))*100\n",
    "\n",
    "    popular_predictors = dataset_predictors.set_index('features')\n",
    "    # Reindex your nodes to match the graph's nodes\n",
    "    popular_predictors_reind = popular_predictors.reindex(G.nodes())\n",
    "    #node_colors_reind['group'] = pd.Categorical(node_colors_reind['group'])\n",
    "    popular_predictors_percent = (popular_predictors_reind/((len(omics)-1)*50))*100\n",
    "\n",
    "    individual_totals[dataset] = popular_predictors_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mxenoc/workspace/multiomics-benchmark/results/individual_totals.pkl', 'wb') as f:  \n",
    "    pickle.dump(individual_totals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy for stacked models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list for the results\n",
    "results_all = list()\n",
    "n_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalearner_list = list()\n",
    "metalearner_list.append(['opt', 'Lasso', False])\n",
    "metalearner_list.append(['opt', 'Lasso', True])\n",
    "metalearner_list.append(['opt', 'EN', False])\n",
    "metalearner_list.append(['opt', 'EN', True])\n",
    "metalearner_list.append(['regular', 'RF', False])\n",
    "metalearner_list.append(['opt', 'Ridge', False])\n",
    "metalearner_list.append(['nnls', 'nnls', False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalearner_list = list()\n",
    "metalearner_list.append(['regular', 'lasso', False])\n",
    "metalearner_list.append(['regular', 'lasso', True])\n",
    "metalearner_list.append(['regular', 'EN', False])\n",
    "metalearner_list.append(['regular', 'EN', True])\n",
    "metalearner_list.append(['regular', 'RF', False])\n",
    "metalearner_list.append(['regular', 'ridge', False])\n",
    "metalearner_list.append(['nnls', 'nnls', False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 1/15 [00:25<05:54, 25.31s/it]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:58<06:00, 27.71s/it]\u001b[A\n",
      " 20%|██        | 3/15 [01:25<05:28, 27.41s/it]\u001b[A\n",
      " 27%|██▋       | 4/15 [01:51<04:58, 27.14s/it]\u001b[A\n",
      " 33%|███▎      | 5/15 [02:16<04:24, 26.46s/it]\u001b[A\n",
      " 40%|████      | 6/15 [02:42<03:55, 26.17s/it]\u001b[A\n",
      " 47%|████▋     | 7/15 [03:09<03:32, 26.59s/it]\u001b[A\n",
      " 53%|█████▎    | 8/15 [03:35<03:04, 26.37s/it]\u001b[A\n",
      " 60%|██████    | 9/15 [04:12<02:57, 29.61s/it]\u001b[A\n",
      " 67%|██████▋   | 10/15 [04:34<02:16, 27.34s/it]\u001b[A\n",
      " 73%|███████▎  | 11/15 [05:04<01:52, 28.09s/it]\u001b[A\n",
      " 80%|████████  | 12/15 [05:26<01:18, 26.32s/it]\u001b[A\n",
      " 87%|████████▋ | 13/15 [05:57<00:55, 27.61s/it]\u001b[A\n",
      " 93%|█████████▎| 14/15 [06:26<00:28, 28.09s/it]\u001b[A\n",
      "100%|██████████| 15/15 [06:47<00:00, 27.20s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "r_p_all = []\n",
    "\n",
    "for dataset_index in tqdm(range(len(datasets))):\n",
    "\n",
    "    dataset = datasets[dataset_index]\n",
    "    omics = options[dataset]\n",
    "\n",
    "    os.chdir('/home/mxenoc/workspace/multiomics-benchmark/results/'+dataset)\n",
    "\n",
    "    feats_list = []\n",
    "\n",
    "    for i in range(len(omics)): \n",
    "        feats_list.append(np.tile(omics[i],n_samples))\n",
    "\n",
    "    feats = np.hstack(feats_list)\n",
    "\n",
    "    metalearner_names= list()\n",
    "    for k in range(len(metalearner_list)):\n",
    "        metalearner_names.append(metalearner_list[k][0]+'_'+metalearner_list[k][1]+'_'+str(metalearner_list[k][2]))\n",
    "\n",
    "    with open(\"Stacked_Lasso.pkl\", 'rb') as f:\n",
    "        mdl = pickle.load(f)\n",
    "\n",
    "    r_p_list = []\n",
    "    #res = defaultdict(list)\n",
    "    models_res = []\n",
    "\n",
    "    res = []    \n",
    "    for metalearners in range(len(metalearner_names)):\n",
    "        all_features = defaultdict(list)\n",
    "        for l in range(len(omics)):\n",
    "            each_feature = defaultdict(list)\n",
    "\n",
    "            for k in range(n_samples):\n",
    "\n",
    "                x = mdl['observed_test'][l][k]\n",
    "                y = pd.concat(mdl['prediction_test'][l][k][metalearner_names[metalearners]])\n",
    "                y.iloc[0,0] += 0.0000000001\n",
    "\n",
    "                each_feature['r'].append(stats.spearmanr(x,y)[0])                \n",
    "                each_feature['p'].append(stats.spearmanr(x,y)[1])\n",
    "\n",
    "            all_features['r'].append(each_feature['r'])\n",
    "            all_features['p'].append(each_feature['p'])\n",
    "\n",
    "        r = np.hstack(all_features['r'])\n",
    "        p = np.hstack(all_features['p'])\n",
    "\n",
    "        r_p = pd.DataFrame({'r': r, 'p': p, 'omics': feats, 'model': metalearner_names[metalearners], 'data' : dataset})\n",
    "        r_p = r_p[(r_p['r']>r_limit) & (r_p['p']<=0.05)]\n",
    "        r_p_list.append(r_p)\n",
    "        res.append(len(r_p))\n",
    "\n",
    "    results = pd.DataFrame({'features': np.hstack(res), 'models': np.hstack(metalearner_names), 'dataset': dataset})\n",
    "    results['percentage'] = results['features']/(len(omics)*n_samples)*100\n",
    "\n",
    "    results_all.append(results)\n",
    "    \n",
    "    r_p_all.append(pd.concat(r_p_list))\n",
    "\n",
    "    os.chdir('/home/mxenoc/workspace/multiomics-benchmark/plots/accuracy_calculations/'+r_limit_name+'/stacked')\n",
    "    with open(dataset+'.pkl', 'wb') as f:  \n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
