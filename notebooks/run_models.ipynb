{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_THREAD_LIMIT=1\n",
      "env: OMP_NUM_THREADS=1\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%env OMP_THREAD_LIMIT = 1\n",
    "%env OMP_NUM_THREADS = 1\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import multiomics_benchmark.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'head_neck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/multiomics-benchmark/data/RData/'+dataset)\n",
    "\n",
    "with open('DF.pkl', 'rb') as f:\n",
    "    DF = pickle.load(f)\n",
    "    \n",
    "with open('groups.pkl', 'rb') as f:\n",
    "    patient_groups = pickle.load(f)\n",
    "    \n",
    "with open('responses.pkl', 'rb') as f:\n",
    "    responses = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = defaultdict(lambda: [\"Meth450_Gene\", \"miRNA_HiSeq_Gene\", \"RNA_HiSeq_Gene\", \"RPPA_Gene\", \"SCNV_Log_Gene\"], \n",
    "                      {'pregnancy': ['rna', 'plasma_l', 'serum_l', 'microb', 'immune', 'metabol', 'plasma_s'],\n",
    "                       'omics': ['rna', 'plasma_l', 'serum_l', 'microb', 'immune', 'metabol', 'plasma_s'],\n",
    "                       'brain':['Meth450_Gene', 'miRNA_Gene', 'RNA_HiSeq_Gene', 'RPPA_Gene', 'SCNV_Log_Gene'],\n",
    "                       'pree': ['rna', 'lipid', 'plasma', 'urine', 'somalog', 'microb'],\n",
    "                       'PreE': ['rna', 'lipid', 'plasma', 'urine', 'somalog', 'microb'],\n",
    "                       'glioma': [\"Meth450_Gene\", \"miRNA_Gene\", \"RNA_HiSeq_Gene\", \"RPPA_Gene\", \"SCNV_Log_Gene\"],\n",
    "                       'ovarian': [\"Meth27_Gene\", \"miRNA_Gene\", \"RNA_GA_Gene\", \"RPPA_Gene\", \"SCNV_Log_Gene\"],\n",
    "                       'uterine':[\"Meth450_Gene\", \"miRNA_HiSeq_Gene\", \"RPPA_Gene\", \"SCNV_Log_Gene\"]\n",
    "                      })\n",
    "\n",
    "omic_names = options[dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = defaultdict(lambda: False, \n",
    "                      {'omics':  True,\n",
    "                       'PreE':  True})\n",
    "\n",
    "longitudinal = options[dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 64548)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick the model type and optimisation method\n",
    "#type_model = 'group_lasso'\n",
    "type_model = 'Stacked_Lasso'\n",
    "\n",
    "folds = 10\n",
    "scale_y = False\n",
    "repeats = 1\n",
    "n_samples = 50\n",
    "tries = 50\n",
    "cv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run stacked lasso\n",
    "results = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omic_names))):\n",
    "    \n",
    "    # Get your feature groups\n",
    "    feature_groups = multiomics_benchmark.models.get_feature_groups(DF, omic_names, predictor_index)\n",
    "    feature_groups_list = multiomics_benchmark.models.get_feature_groups(DF, omic_names, predictor_index)\n",
    "\n",
    "    # Get your y\n",
    "    X, y = multiomics_benchmark.models.get_X_y(DF, omic_names, predictor_index, responses)\n",
    "    \n",
    "    omic_names_left = omic_names.copy()\n",
    "    del omic_names_left[predictor_index]\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(multiomics_benchmark.models.Stacked_Lasso)(X, y, omic_names_left, feat_n, \n",
    "                                                                                   responses, patient_groups, \n",
    "                                                                                   longitudinal, folds, repeats, \n",
    "                                                                                   tries, cv)\n",
    "                            for feat_n in range(n_samples)))\n",
    "        \n",
    "    results['prediction_train'].append(prediction_train)\n",
    "    results['observed_train'].append(observed_train)\n",
    "    results['prediction_test'].append(prediction_test)\n",
    "    results['observed_test'].append(observed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/mxenoc/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/mxenoc/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/mxenoc/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/mxenoc/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/mxenoc/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/mxenoc/workspace/multiomics-benchmark/src/multiomics_benchmark/models.py\", line 850, in SGLasso\n    y = y[:, feat_n]\nIndexError: index 10 is out of bounds for axis 1 with size 10\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-879d639d69d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                                              \u001b[0mpatient_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitudinal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                                              folds, repeats, tries, cv)\n\u001b[0;32m---> 19\u001b[0;31m                             for feat_n in range(n_samples)))\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 1 with size 10"
     ]
    }
   ],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omic_names))):\n",
    "    \n",
    "    # Get your feature groups\n",
    "    feature_groups = multiomics_benchmark.models.get_feature_groups(DF, omic_names, predictor_index)\n",
    "    feature_groups_list = multiomics_benchmark.models.get_feature_groups(DF, omic_names, predictor_index)\n",
    "\n",
    "    # Get your y\n",
    "    X, y = multiomics_benchmark.models.get_X_y(DF, omic_names, predictor_index, responses)\n",
    "    \n",
    "    omic_names_left = omic_names.copy()\n",
    "    del omic_names_left[predictor_index]\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(multiomics_benchmark.models.SGLasso)(X, y, feat_n, feature_groups,  \n",
    "                                                                             patient_groups, longitudinal, \n",
    "                                                                             folds, repeats, tries, cv)\n",
    "                            for feat_n in range(n_samples)))\n",
    "        \n",
    "    results['prediction_train'].append(prediction_train)\n",
    "    results['observed_train'].append(observed_train)\n",
    "    results['prediction_test'].append(prediction_test)\n",
    "    results['observed_test'].append(observed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omic_names))):\n",
    "    \n",
    "    # Get your feature groups\n",
    "    feature_groups = multiomics_benchmark.models.get_feature_groups(DF, omic_names, predictor_index)\n",
    "    feature_groups_list = multiomics_benchmark.models.get_feature_groups(DF, omic_names, predictor_index)\n",
    "\n",
    "    # Get your y\n",
    "    X, y = multiomics_benchmark.models.get_X_y(DF, omic_names, predictor_index, responses)\n",
    "\n",
    "    omic_names_left = omic_names.copy()\n",
    "    del omic_names_left[predictor_index]\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = multiomics_benchmark.models.GFA(\n",
    "        X, y, omic_names_left, patient_groups, longitudinal, folds, repeats, tries, cv)\n",
    "        \n",
    "    results['prediction_train'].append(prediction_train)\n",
    "    results['observed_train'].append(observed_train)\n",
    "    results['prediction_test'].append(prediction_test)\n",
    "    results['observed_test'].append(observed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omic_names))):\n",
    "    \n",
    "    # Get your feature groups\n",
    "    feature_groups = multiomics_benchmark.models.get_feature_groups(DF, omic_names, predictor_index)\n",
    "    feature_groups_list = multiomics_benchmark.models.get_feature_groups(DF, omic_names, predictor_index)\n",
    "\n",
    "    # Get your y\n",
    "    X, y = multiomics_benchmark.models.get_X_y(DF, omic_names, predictor_index, responses)\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(multiomics_benchmark.models.pymodels)(X, y, type_model, feat_n, \n",
    "                                                                              patient_groups, longitudinal, \n",
    "                                                                              folds, repeats, tries, cv)\n",
    "                            for feat_n in range(n_samples)))\n",
    "        \n",
    "    results['prediction_train'].append(prediction_train)\n",
    "    results['observed_train'].append(observed_train)\n",
    "    results['prediction_test'].append(prediction_test)\n",
    "    results['observed_test'].append(observed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/benchmark/results/'+dataset)\n",
    "with open(type_model+'.pkl', 'wb') as f:  \n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
